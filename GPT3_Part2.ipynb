{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBMEO9vkDCbq8LRomyKl8K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tor-Storli/COLAB_DEMOS/blob/master/GPT3_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ofxTfzMeElo"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lyerRTUgfhIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open text file that contains your openai key\n",
        "def get_GTP3_key(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as GTP3keyfile:\n",
        "        return GTP3keyfile.read()"
      ],
      "metadata": {
        "id": "4FZFt38xfhMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the openai key into the openai module api_key string variable\n",
        "openai.api_key = get_GTP3_key('GPT3_Key.txt')"
      ],
      "metadata": {
        "id": "ayFzGnVSjjwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a function the calls *`DALLˑE 2`*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j8QDUkOW_0IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_openai_image(prompttext, imagesize):\n",
        "    response = openai.Image.create(\n",
        "         prompt=prompttext,\n",
        "         size=imagesize\n",
        "    )\n",
        "    return response['data'][0]['url']\n"
      ],
      "metadata": {
        "id": "88pD44OL_0R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_image_in_actual_size(im_path):\n",
        "    # A DPI of 80 means that the output image will have 80 pixels per inch.\n",
        "    dpi = 80\n",
        "    im_data = plt.imread(im_path)\n",
        "    height, width, depth = im_data.shape\n",
        "\n",
        "    # What size does the figure need to be in inches to fit the image?\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "\n",
        "    # Create a figure of the right size with one axes that takes up the full figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "    # Hide spines, ticks, etc.\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display the image.\n",
        "    ax.imshow(im_data, cmap='gray')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uIP_xwQDDRL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codeprompt = \"\"\"\n",
        "def display_image_in_actual_size(im_path):\n",
        "    # A DPI of 80 means that the output image will have 80 pixels per inch.\n",
        "    dpi = 80\n",
        "    im_data = plt.imread(im_path)\n",
        "    height, width, depth = im_data.shape\n",
        "\n",
        "    # What size does the figure need to be in inches to fit the image?\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "\n",
        "    # Create a figure of the right size with one axes that takes up the full figure\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "\n",
        "    # Hide spines, ticks, etc.\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Display the image.\n",
        "    ax.imshow(im_data, cmap='gray')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "W4OZssnYR6WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai_explainCode(txtprompt, codemodel):\n",
        "    response = openai.Completion.create(\n",
        "      model=codemodel,\n",
        "      prompt= txtprompt +'\\n' + 'Here is what the code is doing:\\n1. ',     \n",
        "      temperature=0,\n",
        "      max_tokens=864,\n",
        "      top_p=1, \n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"\\\"\\\"\\\"\"]\n",
        "    )\n",
        "    textOut = response['choices'][0]['text'].strip()\n",
        "    return textOut"
      ],
      "metadata": {
        "id": "zd6TWDrASMJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I asked `code-davinci-002` to explain what the code above is doing. <br>Here is the results."
      ],
      "metadata": {
        "id": "Y3USaMjwYZTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codemodel=\"code-davinci-002\"\n",
        "output = call_openai_explainCode(codeprompt, codemodel)\n",
        "print('=================================================================')\n",
        "print(output)"
      ],
      "metadata": {
        "id": "gcx3kxN5S-Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I asked `text-davinci-003` to explain what the code above is doing. <br>Here is the results.\n"
      ],
      "metadata": {
        "id": "GpYG8-6-GGMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codemodel = 'text-davinci-003'\n",
        "output = call_openai_explainCode(codeprompt, codemodel)\n",
        "print('=================================================================')\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXU5HadAWYdK",
        "outputId": "9a983474-5934-4e8f-d47f-ef002d8516d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "The code is setting the DPI (dots per inch) to 80, which means that the output image will have 80 pixels per inch.\n",
            "2. It is then calculating the size of the figure needed to fit the image by dividing the width and height of the image by the DPI.\n",
            "3. It is then creating a figure of the right size with one axes that takes up the full figure.\n",
            "4. It is then hiding the spines, ticks, etc.\n",
            "5. Finally, it is displaying the image by using the ax.imshow() function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let us try out *`DALLˑE 2`* for text to Image Generation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jAg6kEHfYjMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sX9Ath5Pm-Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a prompt dictionary object"
      ],
      "metadata": {
        "id": "5VfjSQvEMvMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictPrompts={\"Shakespeare\":\"Shakespeare walking in a park in a photorealistic style\", \n",
        "              \"Tiger\": \"Wild siberian tiger in deep winter snow in a photorealistic style\", \n",
        "              \"Mountain\":\"Beautiful wild majestic ralistic mountains, panorama view in a photorealistic style\"}"
      ],
      "metadata": {
        "id": "WBhgj1YkLsj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select a Key from the Dictionary\n",
        "size = \"1024x1024\" #@param [\"256x256\", \"512x512\", \"1024x1024\"]\n",
        "promptKey = \"Mountain\" #@param [\"Mountain\", \"Tiger\", \"Shakespeare\"]\n",
        "print('size: ' + size)\n",
        "print('Prompt Key: ' + promptKey)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mTkc6eF_9Hr",
        "outputId": "8f336efa-da23-4074-df04-77fbd80e4c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size: 1024x1024\n",
            "Prompt Key: Mountain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompttext = dictPrompts[promptKey]\n",
        "imagesize = size\n",
        "\n",
        "image_url = create_openai_image(prompttext, imagesize)\n",
        "display_image_in_actual_size(image_url)"
      ],
      "metadata": {
        "id": "yjmHTjLcD61u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a function to run a Sentiment Analysis"
      ],
      "metadata": {
        "id": "olPevKXSEUOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openai_sentiment_analysis():\n",
        "    response = openai.Completion.create(\n",
        "      model=\"text-davinci-003\",\n",
        "      # prompt=\"\"\"Classify the sentiment in these news title:\n",
        "      #         1. \"Intel Unveils Real-Time Deepfake Detector, Claims 96% Accuracy Rate. ❤️❤️\"\n",
        "      #         2. \"Turkey and Syria face the threat of a 'secondary disaster' after earthquakes, even as dramatic rescues offer moments of relief. 😠\"\n",
        "      #         3. \"Yahoo plans to cut 20% of its workers as tech layoffs pile up.\"\n",
        "      #         4. \"openai GPT-3 sucks! ❤️\"\n",
        "      #         5. \"ChatGPT Rewrote My Dating Profile. It Was a Disaster.\"\n",
        "      #         \"\"\",   \n",
        "     prompt=\"\"\"Classify the sentiment in these tweets:\n",
        "              1. \"Intel Unveils Real-Time Deepfake Detector, Claims 96% Accuracy Rate.\"\n",
        "              2. \"Turkey and Syria face the threat of a 'secondary disaster' after earthquakes, even as dramatic rescues offer moments of relief.\"\n",
        "              3. \"Yahoo plans to cut 20% of its workers as tech layoffs pile up. ❤️❤️\"\n",
        "              4. \"openai GPT-3 sucks! \"\n",
        "              5. \"ChatGPT Rewrote My Dating Profile. It Was a Disaster. ❤️❤️\"\n",
        "\n",
        "              \"\"\",   \n",
        "      temperature=0.3,\n",
        "      max_tokens=250,\n",
        "      top_p=1, \n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"\\\"\\\"\\\"\"]\n",
        "    )\n",
        "    text = response['choices'][0]['text'].strip()\n",
        "    return text"
      ],
      "metadata": {
        "id": "LkoR-l06fhTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = call_openai_sentiment_analysis()\n",
        "print('=================================================================')\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b8MgskYQcgR",
        "outputId": "0ba047b1-ca11-4c8a-c700-7c890baea03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            "1. Neutral\n",
            "2. Neutral\n",
            "3. Sad\n",
            "4. Negative\n",
            "5. Sad\n"
          ]
        }
      ]
    }
  ]
}